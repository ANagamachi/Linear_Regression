# Linear_Regression
There is two linear regression methds, that is solving normal equation and gradient descent.  

## Linear_Regression.pyについて  
### プログラムの説明
訓練データを一度にすべて用いるバッチ勾配降下法を用いて，フィッティング関数を$y=ax+b$の線形関数とする回帰．線形単回帰を行う．  
データは[0, 10]を範囲とする説明変数$x$に対し$y=ax+b+\epsilon$で計算される目的変数$y$の組とする．  
  
プログラムを実行すると，各エポックごとの誤差の勾配ベクトル'gradients'と回帰直線のパラメータ'theta'がコマンドライン上に出力され，学習に際し勾配が発散し
ていないかを確かめることができる．  
学習が終了すると回帰直線の式とテスト誤差がコマンドライン上に出力される．  
'learn_curve.png'にエポック数ごとの訓練誤差と検証誤差を示した学習曲線が可視化されており，訓練誤差が低下しているのに対し検証誤差が増加する過学習が起きて
いないかを確かめることができる．  
また，実行後に回帰直線（直線）がテストデータ（赤の点）に徐々に近づく描画が行われる．  
